{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### divide the data into training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import os\n",
    "# initialize the path to the *original* input directory of images\n",
    "ORIG_INPUT_DATASET = \"malaria/cell_images\"\n",
    "# initialize the base path to the *new* directory that will contain\n",
    "# our images after computing the training and testing split\n",
    "BASE_PATH = \"malaria\"\n",
    "# derive the training, validation, and testing directories\n",
    "TRAIN_PATH = os.path.sep.join([BASE_PATH, \"training\"])\n",
    "VAL_PATH = os.path.sep.join([BASE_PATH, \"validation\"])\n",
    "TEST_PATH = os.path.sep.join([BASE_PATH, \"testing\"])\n",
    "# define the amount of data that will be used training\n",
    "TRAIN_SPLIT = 0.8\n",
    "# the amount of validation data will be a percentage of the\n",
    "# *training* data\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "#from pyimagesearch import config\n",
    "from imutils import paths\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "# grab the paths to all input images in the original input directory\n",
    "# and shuffle them\n",
    "imagePaths = list(paths.list_images(ORIG_INPUT_DATASET))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the training and testing split\n",
    "i = int(len(imagePaths) * TRAIN_SPLIT)\n",
    "trainPaths = imagePaths[:i]\n",
    "testPaths = imagePaths[i:]\n",
    "# we'll be using part of the training data for validation\n",
    "i = int(len(trainPaths) * VAL_SPLIT)\n",
    "valPaths = trainPaths[:i]\n",
    "trainPaths = trainPaths[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the datasets that we'll be building\n",
    "datasets = [\n",
    "\t(\"training\", trainPaths, TRAIN_PATH),\n",
    "\t(\"validation\", valPaths, VAL_PATH),\n",
    "\t(\"testing\", testPaths, TEST_PATH)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building 'training' split\n",
      "[INFO] 'creating malaria\\training' directory\n",
      "[INFO] 'creating malaria\\training\\Parasitized' directory\n",
      "[INFO] 'creating malaria\\training\\Uninfected' directory\n",
      "[INFO] building 'validation' split\n",
      "[INFO] 'creating malaria\\validation' directory\n",
      "[INFO] 'creating malaria\\validation\\Parasitized' directory\n",
      "[INFO] 'creating malaria\\validation\\Uninfected' directory\n",
      "[INFO] building 'testing' split\n",
      "[INFO] 'creating malaria\\testing' directory\n",
      "[INFO] 'creating malaria\\testing\\Parasitized' directory\n",
      "[INFO] 'creating malaria\\testing\\Uninfected' directory\n"
     ]
    }
   ],
   "source": [
    "# loop over the datasets\n",
    "for (dType, imagePaths, baseOutput) in datasets:\n",
    "\t# show which data split we are creating\n",
    "\tprint(\"[INFO] building '{}' split\".format(dType))\n",
    "\t# if the output base output directory does not exist, create it\n",
    "\tif not os.path.exists(baseOutput):\n",
    "\t\tprint(\"[INFO] 'creating {}' directory\".format(baseOutput))\n",
    "\t\tos.makedirs(baseOutput)\n",
    "\t# loop over the input image paths\n",
    "\tfor inputPath in imagePaths:\n",
    "\t\t# extract the filename of the input image along with its\n",
    "\t\t# corresponding class label\n",
    "\t\tfilename = inputPath.split(os.path.sep)[-1]\n",
    "\t\tlabel = inputPath.split(os.path.sep)[-2]\n",
    "\t\t# build the path to the label directory\n",
    "\t\tlabelPath = os.path.sep.join([baseOutput, label])\n",
    "\t\t# if the label output directory does not exist, create it\n",
    "\t\tif not os.path.exists(labelPath):\n",
    "\t\t\tprint(\"[INFO] 'creating {}' directory\".format(labelPath))\n",
    "\t\t\tos.makedirs(labelPath)\n",
    "\t\t# construct the path to the destination image and then copy\n",
    "\t\t# the image itself\n",
    "\t\tp = os.path.sep.join([labelPath, filename])\n",
    "\t\tshutil.copy2(inputPath, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights = \"imagenet\",\n",
    "include_top = False)\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1 / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19842 images belonging to 2 classes.\n",
      "Found 5512 images belonging to 2 classes.\n",
      "Found 2204 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "height=64\n",
    "width=64\n",
    "channels=3 \n",
    "batch_size=32\n",
    "seed = 1234\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range = 30, \n",
    "                             rescale=1. / 255,  \n",
    "                             shear_range=0.2,  \n",
    "                             zoom_range=0.1, \n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode=\"nearest\",  \n",
    "                            )\n",
    "\n",
    "\n",
    "train_data = datagen.flow_from_directory(directory=TRAIN_PATH, \n",
    "                                         target_size  = (height,width), \n",
    "                                         batch_size=batch_size, \n",
    "                                         seed=seed,  \n",
    "                                         class_mode=\"binary\", \n",
    "                                        )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  \n",
    "test_data = test_datagen.flow_from_directory(directory=TEST_PATH, \n",
    "                                             target_size=(height,width), \n",
    "                                             batch_size=batch_size,\n",
    "                                             seed=seed,\n",
    "                                             class_mode=\"binary\")\n",
    "\n",
    "val_data = test_datagen.flow_from_directory(directory=VAL_PATH, \n",
    "                                             target_size=(height,width), \n",
    "                                             batch_size=batch_size,\n",
    "                                             seed=seed,\n",
    "                                             class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model2 = VGG16(weights='imagenet',\n",
    "                         include_top=False, \n",
    "                        )\n",
    "base_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(base_model,sample_count, datagen):\n",
    "    start = time()\n",
    "    features =  np.zeros(shape=(sample_count, 2, 2, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen\n",
    "    batch_size = generator.batch_size\n",
    "    #print(batch_size)\n",
    "    i = 0\n",
    "    for inputs_batch,labels_batch in generator:\n",
    "        stop = time()\n",
    "        times = stop - start\n",
    "        print('\\r',\n",
    "              'Extracting features from batch', str(i+1), '/', len(datagen),\n",
    "              '-- run time:', times,'seconds',\n",
    "              end='')\n",
    "        \n",
    "        features_batch = base_model.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        \n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "            \n",
    "    print(\"\\n\")\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracting features from batch 621 / 621 -- run time: 225.8938112258911 secondss\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "train_features, train_labels = extract_features(base_model2,19842, train_data)\n",
    "test_features, test_labels = extract_features(base_model2,5512, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracting features from batch 69 / 69 -- run time: 21.61341094970703 secondss\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_features, val_labels = extract_features(base_model2, 2204, val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_features', train_features)\n",
    "np.save('test_features', test_features)\n",
    "np.save('val_features', val_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.load('train_features.npy')\n",
    "test_features = np.load('test_features.npy') \n",
    "validation_features = np.load('val_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (19842, 2 * 2 * 512))\n",
    "test_features = np.reshape(test_features, (5512, 2 * 2 * 512))\n",
    "val_features = np.reshape(validation_features, (2204, 2 * 2 * 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor the top classification layers of VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 656,385\n",
      "Trainable params: 656,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation = \"relu\", input_dim = (2*2*512)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation = \"relu\"))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "4961/4961 [==============================] - 18s 4ms/step - loss: 0.1961 - accuracy: 0.9237 - val_loss: 0.2249 - val_accuracy: 0.9224\n",
      "Epoch 2/25\n",
      "4961/4961 [==============================] - 16s 3ms/step - loss: 0.1887 - accuracy: 0.9282 - val_loss: 0.2178 - val_accuracy: 0.9324\n",
      "Epoch 3/25\n",
      "4961/4961 [==============================] - 15s 3ms/step - loss: 0.1906 - accuracy: 0.9283 - val_loss: 0.2110 - val_accuracy: 0.9342\n",
      "Epoch 4/25\n",
      "4961/4961 [==============================] - 14s 3ms/step - loss: 0.1897 - accuracy: 0.9268 - val_loss: 0.2189 - val_accuracy: 0.9387\n",
      "Epoch 5/25\n",
      "4961/4961 [==============================] - 14s 3ms/step - loss: 0.1914 - accuracy: 0.9260 - val_loss: 0.2276 - val_accuracy: 0.9170\n",
      "Epoch 6/25\n",
      "4961/4961 [==============================] - 14s 3ms/step - loss: 0.1903 - accuracy: 0.9288 - val_loss: 0.2182 - val_accuracy: 0.9333\n",
      "Epoch 7/25\n",
      "4961/4961 [==============================] - 14s 3ms/step - loss: 0.1883 - accuracy: 0.9296 - val_loss: 0.1923 - val_accuracy: 0.9333\n",
      "Epoch 8/25\n",
      "4961/4961 [==============================] - 14s 3ms/step - loss: 0.1897 - accuracy: 0.9263 - val_loss: 0.2074 - val_accuracy: 0.9378\n",
      "Epoch 9/25\n",
      "4961/4961 [==============================] - 15s 3ms/step - loss: 0.1905 - accuracy: 0.9270 - val_loss: 0.2059 - val_accuracy: 0.9378\n",
      "Epoch 10/25\n",
      "4961/4961 [==============================] - 14s 3ms/step - loss: 0.1872 - accuracy: 0.9286 - val_loss: 0.2051 - val_accuracy: 0.9383\n",
      "Epoch 11/25\n",
      "4961/4961 [==============================] - 14s 3ms/step - loss: 0.1874 - accuracy: 0.9275 - val_loss: 0.1987 - val_accuracy: 0.9369\n",
      "Epoch 12/25\n",
      "4961/4961 [==============================] - 16s 3ms/step - loss: 0.1853 - accuracy: 0.9273 - val_loss: 0.2103 - val_accuracy: 0.9260\n",
      "Epoch 13/25\n",
      "4961/4961 [==============================] - 24s 5ms/step - loss: 0.1875 - accuracy: 0.9293 - val_loss: 0.2138 - val_accuracy: 0.9347\n",
      "Epoch 14/25\n",
      "4961/4961 [==============================] - 16s 3ms/step - loss: 0.1864 - accuracy: 0.9281 - val_loss: 0.1984 - val_accuracy: 0.9292\n",
      "Epoch 15/25\n",
      "4961/4961 [==============================] - 15s 3ms/step - loss: 0.1856 - accuracy: 0.9276 - val_loss: 0.2158 - val_accuracy: 0.9333\n",
      "Epoch 16/25\n",
      "4961/4961 [==============================] - 15s 3ms/step - loss: 0.1854 - accuracy: 0.9304 - val_loss: 0.2233 - val_accuracy: 0.9356\n",
      "Epoch 17/25\n",
      "4961/4961 [==============================] - 15s 3ms/step - loss: 0.1845 - accuracy: 0.9301 - val_loss: 0.1916 - val_accuracy: 0.9347\n",
      "Epoch 18/25\n",
      "4961/4961 [==============================] - 15s 3ms/step - loss: 0.1851 - accuracy: 0.9283 - val_loss: 0.2047 - val_accuracy: 0.9251\n",
      "Epoch 19/25\n",
      "4961/4961 [==============================] - 15s 3ms/step - loss: 0.1841 - accuracy: 0.9304 - val_loss: 0.1966 - val_accuracy: 0.9342\n",
      "Epoch 20/25\n",
      "4961/4961 [==============================] - 15s 3ms/step - loss: 0.1855 - accuracy: 0.9288 - val_loss: 0.1969 - val_accuracy: 0.9342\n",
      "Epoch 21/25\n",
      "4961/4961 [==============================] - 17s 3ms/step - loss: 0.1828 - accuracy: 0.9310 - val_loss: 0.2096 - val_accuracy: 0.9360\n",
      "Epoch 22/25\n",
      "4961/4961 [==============================] - 15s 3ms/step - loss: 0.1806 - accuracy: 0.9302 - val_loss: 0.1961 - val_accuracy: 0.9279\n",
      "Epoch 23/25\n",
      "4961/4961 [==============================] - 14s 3ms/step - loss: 0.1838 - accuracy: 0.9310 - val_loss: 0.1980 - val_accuracy: 0.9356\n",
      "Epoch 24/25\n",
      "4961/4961 [==============================] - 15s 3ms/step - loss: 0.1819 - accuracy: 0.9289 - val_loss: 0.2798 - val_accuracy: 0.8984\n",
      "Epoch 25/25\n",
      "4961/4961 [==============================] - 14s 3ms/step - loss: 0.1833 - accuracy: 0.9301 - val_loss: 0.1857 - val_accuracy: 0.9415\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(SGD(learning_rate=0.01),loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_fit = model.fit(train_features, train_labels,batch_size=4,\n",
    "                      validation_data=(val_features, val_labels),  \n",
    "                      epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.9399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17743372917175293, 0.9399492144584656]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_features,test_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The model accuracy is 93.99% on the test dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
